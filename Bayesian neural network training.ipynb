{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "#from savedir import *\n",
    "#from utils import *\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as nnf\n",
    "import torch.optim as torchopt\n",
    "import torch.distributions.constraints as constraints\n",
    "softplus = torch.nn.Softplus()\n",
    "\n",
    "import pyro\n",
    "from pyro import poutine\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceMeanField_ELBO, Predictive\n",
    "import pyro.optim as pyroopt\n",
    "from pyro.infer.mcmc import MCMC, HMC, NUTS\n",
    "from pyro.distributions import OneHotCategorical, Normal, Categorical, Uniform\n",
    "from pyro.nn import PyroModule\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: {}'.format(device))\n",
    "if torch.cuda.is_available():\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(dict, path):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, figsize=(12,8))\n",
    "    ax1.plot(dict['loss'])\n",
    "    ax1.set_title(\"loss\")\n",
    "    ax2.plot(dict['accuracy'])\n",
    "    ax2.set_title(\"accuracy\")\n",
    "#    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "#    fig.savefig(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "\n",
    "    def __init__(self, dataset_name, input_shape, output_size, activation, \n",
    "                 architecture, lr, epochs):\n",
    "\n",
    "#        if math.log(hidden_size, 2).is_integer() is False or hidden_size<16:\n",
    "#            raise ValueError(\"\\nhidden size should be a power of 2 greater than 16.\")\n",
    "\n",
    "        super(NN, self).__init__()\n",
    "        self.dataset_name = dataset_name\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "        # self.loss_func = nn.NLLLoss()\n",
    "        self.architecture = architecture\n",
    "#        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.activation = activation\n",
    "        self.lr, self.epochs = lr, epochs\n",
    "\n",
    "#        self.name = self.get_name(dataset_name, hidden_size, activation, architecture, lr, epochs)\n",
    "        self.set_model(architecture, activation, input_shape, output_size)\n",
    "        # print(\"\\nTotal number of weights =\", sum(p.numel() for p in self.parameters()))\n",
    "\n",
    "    def get_name(self, dataset_name, activation, architecture, lr, epochs):\n",
    "        return str(dataset_name)+\"_act=\"+str(activation)+\\\n",
    "               \"_arch=\"+str(architecture)+\"_ep=\"+str(epochs)+\"_lr=\"+str(lr)\n",
    "\n",
    "    def set_model(self, architecture, activation, input_shape, output_size):\n",
    "\n",
    "        input_size = input_shape[0]*input_shape[1]*input_shape[2]\n",
    "        in_channels = input_shape[0]\n",
    "        n_classes = output_size\n",
    "\n",
    "        if activation == \"relu\":\n",
    "            activ = nn.ReLU\n",
    "        elif activation == \"leaky\":\n",
    "            activ = nn.LeakyReLU\n",
    "        elif activation == \"sigm\":\n",
    "            activ = nn.Sigmoid\n",
    "        elif activation == \"tanh\":\n",
    "            activ = nn.Tanh\n",
    "        else: \n",
    "            raise AssertionError(\"\\nWrong activation name.\")\n",
    "\n",
    "        if architecture == \"fc\":\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(input_size, 100),\n",
    "                activ(),\n",
    "                nn.Linear(100, output_size))\n",
    "            \n",
    "        elif architecture == \"custom\":\n",
    "            self.model = nn.Sequential(nn.Conv2d(in_channels= in_channels,\n",
    "                                                 out_channels=64,\n",
    "                                                 kernel_size=5,\n",
    "                                                 ),\n",
    "                                       activ(),\n",
    "                                       nn.MaxPool2d(2,2),\n",
    "                                       #nn.BatchNorm2d(64),\n",
    "                                       nn.Conv2d(in_channels=64,\n",
    "                                                 out_channels=512,\n",
    "                                                 kernel_size=3,\n",
    "                                                 ),\n",
    "                                       activ(),\n",
    "                                       nn.MaxPool2d(2,2),\n",
    "                                       #nn.Dropout(p=0.3),\n",
    "                                       #nn.Conv2d(in_channels=512,\n",
    "                                       #          out_channels=1024,\n",
    "                                       #          kernel_size=3,\n",
    "                                       #          ),\n",
    "                                       #activ(),\n",
    "                                       #nn.MaxPool2d(2,2),\n",
    "                                       #nn.BatchNorm2d(1024),\n",
    "                                       #nn.Dropout(p=0.4),\n",
    "                                       #nn.Conv2d(in_channels=1024,\n",
    "                                       #          out_channels=1024,\n",
    "                                       #          kernel_size=2,\n",
    "                                       #          ),\n",
    "                                       #activ(),\n",
    "                                       #nn.MaxPool2d(2,2),\n",
    "                                       #nn.Dropout(p=0.4),\n",
    "                                       nn.Flatten(),\n",
    "                                       nn.Linear(512*5*5, 256),\n",
    "                                       #nn.Dropout(p=0.5),\n",
    "                                       nn.Linear(256, output_size))\n",
    "\n",
    "        elif architecture == \"conv\":\n",
    "\n",
    "            if self.dataset_name not in [\"mnist\",\"fashion_mnist\"]:\n",
    "                raise NotImplementedError()\n",
    "\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, 32, kernel_size=5),\n",
    "                activ(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(32, hidden_size, kernel_size=5),\n",
    "                activ(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(int(hidden_size/(4*4))*input_size, output_size))\n",
    "\n",
    "        elif architecture == \"conv2\":\n",
    "\n",
    "            self.model = nn.Sequential(\n",
    "\n",
    "                nn.Conv2d(in_channels, 32, kernel_size=5),\n",
    "                activ(),\n",
    "                nn.MaxPool2d(kernel_size=2), \n",
    "                nn.Conv2d(32, hidden_size, kernel_size=5),\n",
    "                activ(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "                nn.Flatten(),\n",
    "            )   \n",
    "\n",
    "            self.fc_out = lambda x: nn.Linear(x.size(1), output_size)(x)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def forward(self, inputs, device=None, *args, **kwargs):\n",
    "\n",
    "        device=self.device if device is None else device\n",
    "\n",
    "        self.to(device)\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        if self.architecture == \"conv2\":\n",
    "\n",
    "            x = self.model(inputs)\n",
    "            x = self.fc_out(x)\n",
    "\n",
    "        else:\n",
    "            x = self.model(inputs)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def save(self, savedir=None, seed=None):\n",
    "\n",
    "        name = self.name \n",
    "        directory = name if savedir is None else savedir\n",
    "        filename = name+\"_weights.pt\" if seed is None else name+\"_weights_\"+str(seed)+\".pt\"\n",
    "\n",
    "        os.makedirs(os.path.dirname(TESTS+directory+\"/\"), exist_ok=True)\n",
    "        print(\"\\nSaving: \", TESTS+directory+\"/\"+filename)\n",
    "        torch.save(self.state_dict(), TESTS+directory+\"/\"+filename)\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\"\\nCheck saved weights:\")\n",
    "            print(\"\\nstate_dict()['l2.0.weight'] =\", self.state_dict()[\"l2.0.weight\"][0,0,:3])\n",
    "            print(\"\\nstate_dict()['out.weight'] =\",self.state_dict()[\"out.weight\"][0,:3])\n",
    "\n",
    "    def load(self, device, savedir=None, seed=None, rel_path = None):   #=TESTS\n",
    "        self.device=device\n",
    "\n",
    "        name = self.name\n",
    "        directory = name if savedir is None else savedir\n",
    "        filename = name+\"_weights.pt\" if seed is None else name+\"_weights_\"+str(seed)+\".pt\"\n",
    "\n",
    "        print(\"\\nLoading: \", rel_path+directory+\"/\"+filename)\n",
    "        self.load_state_dict(torch.load(rel_path+directory+\"/\"+filename))\n",
    "        print(\"\\n\", list(self.state_dict().keys()), \"\\n\")\n",
    "        self.to(device)\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\"\\nCheck loaded weights:\")    \n",
    "            print(\"\\nstate_dict()['l2.0.weight'] =\", self.state_dict()[\"l2.0.weight\"][0,0,:3])\n",
    "            print(\"\\nstate_dict()['out.weight'] =\",self.state_dict()[\"out.weight\"][0,:3])\n",
    "\n",
    "    def train(self, train_loader, device, seed=0, save=True):\n",
    "\n",
    "        print(\"\\n == NN training ==\")\n",
    "\n",
    "        self.device=device\n",
    "        self.to(device)\n",
    "\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        optimizer = torchopt.Adam(params=self.parameters(), lr=self.lr)\n",
    "\n",
    "#        start = time.time()\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0.0\n",
    "            correct_predictions = 0.0\n",
    "\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device).argmax(-1)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.forward(x_batch, device)\n",
    "                loss = self.loss_func(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                predictions = outputs.argmax(-1)\n",
    "                correct_predictions += (predictions == y_batch).sum()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            total_loss = total_loss / len(train_loader.dataset)\n",
    "            accuracy = 100 * correct_predictions / len(train_loader.dataset)\n",
    "            print(f\"\\n[Epoch {epoch + 1}]\\t loss: {total_loss:.8f} \\t accuracy: {accuracy:.2f}\", \n",
    "                  end=\"\\t\")\n",
    "\n",
    "#        execution_time(start=start, end=time.time())\n",
    "        \n",
    "        if save:\n",
    "            self.save()\n",
    "\n",
    "    def evaluate(self, test_loader, device, *args, **kwargs):\n",
    "        self.device=device\n",
    "        self.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            correct_predictions = 0.0\n",
    "\n",
    "            for x_batch, y_batch in test_loader:\n",
    "\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device).argmax(-1)\n",
    "                outputs = self(x_batch)\n",
    "                predictions = outputs.argmax(-1)\n",
    "                correct_predictions += (predictions == y_batch).sum()\n",
    "\n",
    "            accuracy = 100 * correct_predictions / len(test_loader.dataset)\n",
    "            print(\"\\nAccuracy: %.2f%%\" % (accuracy))\n",
    "            return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN(PyroModule):\n",
    "\n",
    "    def __init__(self, dataset_name, activation, architecture, inference, \n",
    "                 epochs, lr, n_samples, warmup, input_shape, output_size, \n",
    "                 step_size=0.005, num_steps=10):\n",
    "        super(BNN, self).__init__()\n",
    "        self.dataset_name = dataset_name\n",
    "        self.inference = inference\n",
    "        self.architecture = architecture\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.n_samples = n_samples\n",
    "        self.warmup = warmup\n",
    "        self.step_size = step_size\n",
    "        self.num_steps = num_steps\n",
    "        self.basenet = NN(dataset_name=dataset_name, input_shape=input_shape, output_size=output_size,\n",
    "                          activation=activation, architecture=architecture, epochs=epochs, lr=lr)\n",
    "        # print(self.basenet)\n",
    "        self.name = self.get_name()\n",
    "\n",
    "    def get_name(self, n_inputs=None):\n",
    "        \n",
    "        name = str(self.dataset_name)+\"_bnn_\"+str(self.inference)+\"_act=\"+str(self.basenet.activation)+\\\n",
    "               \"_arch=\"+str(self.basenet.architecture)\n",
    "\n",
    "        if n_inputs:\n",
    "            name = name+\"_inp=\"+str(n_inputs)\n",
    "\n",
    "        if self.inference == \"svi\":\n",
    "            return name+\"_ep=\"+str(self.epochs)+\"_lr=\"+str(self.lr)\n",
    "        elif self.inference == \"hmc\":\n",
    "            return name+\"_samp=\"+str(self.n_samples)+\"_warm=\"+str(self.warmup)+\\\n",
    "                   \"_stepsize=\"+str(self.step_size)+\"_numsteps=\"+str(self.num_steps)\n",
    "\n",
    "    def model(self, x_data, y_data):\n",
    "\n",
    "        priors = {}\n",
    "        for key, value in self.basenet.state_dict().items():\n",
    "            loc = torch.zeros_like(value)\n",
    "            scale = torch.ones_like(value)\n",
    "            prior = Normal(loc=loc, scale=scale)\n",
    "            priors.update({str(key):prior})\n",
    "\n",
    "        lifted_module = pyro.random_module(\"module\", self.basenet, priors)()\n",
    "\n",
    "        with pyro.plate(\"data\", len(x_data)):\n",
    "            logits = lifted_module(x_data)\n",
    "            lhat = nnf.log_softmax(logits, dim=-1)\n",
    "            obs = pyro.sample(\"obs\", Categorical(logits=lhat), obs=y_data)\n",
    "\n",
    "    def guide(self, x_data, y_data=None):\n",
    "\n",
    "        dists = {}\n",
    "        for key, value in self.basenet.state_dict().items():\n",
    "            loc = pyro.param(str(f\"{key}_loc\"), torch.randn_like(value)) \n",
    "            scale = pyro.param(str(f\"{key}_scale\"), torch.randn_like(value))\n",
    "            distr = Normal(loc=loc, scale=softplus(scale))\n",
    "            dists.update({str(key):distr})\n",
    "\n",
    "        lifted_module = pyro.random_module(\"module\", self.basenet, dists)()\n",
    "        \n",
    "        with pyro.plate(\"data\", len(x_data)):\n",
    "            logits = lifted_module(x_data)\n",
    "            preds = nnf.softmax(logits, dim=-1)\n",
    "\n",
    "        return preds\n",
    "\n",
    "    def save(self, rel_path = None, filename=None):    #=TESTS\n",
    "\n",
    "        if filename is None:\n",
    "            filename = self.name+\"_weights\"\n",
    "\n",
    "        path = rel_path + self.name +\"/\"\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "        if self.inference == \"svi\":\n",
    "            self.basenet.to(\"cpu\")\n",
    "            self.to(\"cpu\")\n",
    "\n",
    "            param_store = pyro.get_param_store()\n",
    "            print(\"\\nSaving: \", path + filename +\".pt\")\n",
    "            print(f\"\\nlearned params = {param_store.get_all_param_names()}\")\n",
    "            param_store.save(path + filename +\".pt\")\n",
    "\n",
    "        elif self.inference == \"hmc\":\n",
    "            self.basenet.to(\"cpu\")\n",
    "            self.to(\"cpu\")\n",
    "\n",
    "            for key, value in self.posterior_predictive.items():\n",
    "                torch.save(value.state_dict(), path+filename+\"_\"+str(key)+\".pt\")\n",
    "\n",
    "                if DEBUG:\n",
    "                    print(value.state_dict()[\"model.5.bias\"])\n",
    "\n",
    "    def load(self, device, rel_path = None, filename=None):     #=TESTS\n",
    "\n",
    "        if filename is None:\n",
    "            filename = self.name+\"_weights\"\n",
    "\n",
    "        path = rel_path + self.name +\"/\"\n",
    "\n",
    "        self.device=device\n",
    "        self.basenet.device=device\n",
    "\n",
    "        if self.inference == \"svi\":\n",
    "            param_store = pyro.get_param_store()\n",
    "            param_store.load(path + filename + \".pt\")\n",
    "            for key, value in param_store.items():\n",
    "                param_store.replace_param(key, value.to(device), value)\n",
    "            print(\"\\nLoading \", path + filename + \".pt\\n\")\n",
    "\n",
    "        elif self.inference == \"hmc\":\n",
    "\n",
    "            self.posterior_predictive={}\n",
    "            for model_idx in range(self.n_samples):\n",
    "                net_copy = copy.deepcopy(self.basenet)\n",
    "                net_copy.load_state_dict(torch.load(path+filename+\"_\"+str(model_idx)+\".pt\"))\n",
    "                self.posterior_predictive.update({model_idx:net_copy})      \n",
    "\n",
    "            if len(self.posterior_predictive)!=self.n_samples:\n",
    "                raise AttributeError(\"wrong number of posterior models\")\n",
    "\n",
    "        self.to(device)\n",
    "        self.basenet.to(device)\n",
    "\n",
    "    def forward(self, inputs, n_samples=10, avg_posterior=False, seeds=None):\n",
    "\n",
    "        if seeds:\n",
    "            if len(seeds) != n_samples:\n",
    "                raise ValueError(\"Number of seeds should match number of samples.\")\n",
    "\n",
    "        if self.inference == \"svi\":\n",
    "\n",
    "            if avg_posterior is True:\n",
    "\n",
    "                guide_trace = poutine.trace(self.guide).get_trace(inputs)  \n",
    "\n",
    "                avg_state_dict = {}\n",
    "                for key in self.basenet.state_dict().keys():\n",
    "                    avg_weights = guide_trace.nodes[str(key)+\"_loc\"]['value']\n",
    "                    avg_state_dict.update({str(key):avg_weights})\n",
    "\n",
    "                self.basenet.load_state_dict(avg_state_dict)\n",
    "                preds = [self.basenet.model(inputs)]\n",
    "\n",
    "            else:\n",
    "\n",
    "                preds = []  \n",
    "\n",
    "                if seeds:\n",
    "                    for seed in seeds:\n",
    "                        pyro.set_rng_seed(seed)\n",
    "                        guide_trace = poutine.trace(self.guide).get_trace(inputs)   \n",
    "                        preds.append(guide_trace.nodes['_RETURN']['value'])\n",
    "\n",
    "                else:\n",
    "\n",
    "                    for _ in range(n_samples):\n",
    "                        guide_trace = poutine.trace(self.guide).get_trace(inputs)   \n",
    "                        preds.append(guide_trace.nodes['_RETURN']['value'])\n",
    "\n",
    "                if DEBUG:\n",
    "                    print(\"\\nlearned variational params:\\n\")\n",
    "                    print(pyro.get_param_store().get_all_param_names())\n",
    "                    print(list(poutine.trace(self.guide).get_trace(inputs).nodes.keys()))\n",
    "                    print(\"\\n\", pyro.get_param_store()[\"model.0.weight_loc\"][0][:5])\n",
    "                    print(guide_trace.nodes['module$$$model.0.weight'][\"fn\"].loc[0][:5])\n",
    "                    print(\"posterior sample: \", \n",
    "                      guide_trace.nodes['module$$$model.0.weight']['value'][5][0][0])\n",
    "\n",
    "        elif self.inference == \"hmc\":\n",
    "\n",
    "            preds = []\n",
    "            posterior_predictive = list(self.posterior_predictive.values())\n",
    "\n",
    "            if seeds is None:\n",
    "                seeds = range(n_samples)\n",
    "\n",
    "            for seed in seeds:\n",
    "                net = posterior_predictive[seed]\n",
    "                preds.append(net.forward(inputs))\n",
    "    \n",
    "        output_probs = torch.stack(preds).mean(0)\n",
    "        return output_probs \n",
    "\n",
    "    def _train_hmc(self, train_loader, n_samples, warmup, step_size, num_steps, device, rel_path, filename):\n",
    "\n",
    "        print(\"\\n == HMC training ==\")\n",
    "        pyro.clear_param_store()\n",
    "\n",
    "        num_batches = int(len(train_loader.dataset)/train_loader.batch_size)\n",
    "        batch_samples = int(n_samples/num_batches)+1\n",
    "        print(\"\\nn_batches=\",num_batches,\"\\tbatch_samples =\", batch_samples)\n",
    "\n",
    "        kernel = HMC(self.model, step_size=step_size, num_steps=num_steps)\n",
    "        mcmc = MCMC(kernel=kernel, num_samples=batch_samples, warmup_steps=warmup, num_chains=1)\n",
    "\n",
    "#        start = time.time()\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            labels = y_batch.to(device).argmax(-1)\n",
    "            mcmc.run(x_batch, labels)\n",
    "\n",
    "#        execution_time(start=start, end=time.time())     \n",
    "\n",
    "        self.posterior_predictive={}\n",
    "        posterior_samples = mcmc.get_samples(n_samples)\n",
    "        state_dict_keys = list(self.basenet.state_dict().keys())\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\"\\n\", list(posterior_samples.values())[-1])\n",
    "\n",
    "        for model_idx in range(n_samples):\n",
    "            net_copy = copy.deepcopy(self.basenet)\n",
    "\n",
    "            model_dict=OrderedDict({})\n",
    "            for weight_idx, weights in enumerate(posterior_samples.values()):\n",
    "                model_dict.update({state_dict_keys[weight_idx]:weights[model_idx]})\n",
    "            \n",
    "            net_copy.load_state_dict(model_dict)\n",
    "            self.posterior_predictive.update({str(model_idx):net_copy})\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\"\\n\", weights[model_idx]) \n",
    "\n",
    "        self.save(rel_path=rel_path, filename=filename)\n",
    "\n",
    "    def _train_svi(self, train_loader, epochs, lr, device, rel_path, filename):     # filename -> savedir\n",
    "        self.device=device\n",
    "\n",
    "        print(\"\\n == SVI training ==\")\n",
    "\n",
    "        optimizer = pyro.optim.Adam({\"lr\":lr})\n",
    "        elbo = TraceMeanField_ELBO()\n",
    "        svi = SVI(self.model, self.guide, optimizer, loss=elbo)\n",
    "\n",
    "        loss_list = []\n",
    "        accuracy_list = []\n",
    "\n",
    "#        start = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            loss = 0.0\n",
    "            correct_predictions = 0.0\n",
    "\n",
    "            for x_batch, y_batch in train_loader:\n",
    "\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                labels = y_batch.argmax(-1)\n",
    "                loss += svi.step(x_data=x_batch, y_data=labels)\n",
    "\n",
    "                outputs = self.forward(x_batch, n_samples=10)\n",
    "                predictions = outputs.argmax(dim=-1)\n",
    "                correct_predictions += (predictions == labels).sum().item()\n",
    "            \n",
    "            if DEBUG:\n",
    "                print(\"\\n\", pyro.get_param_store()[\"model.0.weight_loc\"][0][:5])\n",
    "                print(\"\\n\", predictions[:10], \"\\n\", labels[:10])\n",
    "\n",
    "            total_loss = loss / len(train_loader.dataset)\n",
    "            accuracy = 100 * correct_predictions / len(train_loader.dataset)\n",
    "\n",
    "            print(f\"\\n[Epoch {epoch + 1}]\\t loss: {total_loss:.2f} \\t accuracy: {accuracy:.2f}\", \n",
    "                  end=\"\\t\")\n",
    "\n",
    "            loss_list.append(loss)\n",
    "            accuracy_list.append(accuracy)\n",
    "\n",
    "#        execution_time(start=start, end=time.time())\n",
    "#        self.save(rel_path=rel_path, filename=filename)\n",
    "\n",
    "        plot_loss_accuracy(dict={'loss':loss_list, 'accuracy':accuracy_list},\n",
    "                           path = None)   # TESTS+self.name+\"/\"+self.name+\"_training.png\"\n",
    "\n",
    "    def train(self, train_loader, device, rel_path = None, filename=None):   #=TESTS\n",
    "        self.device=device\n",
    "        self.basenet.device=device\n",
    "\n",
    "        self.to(device)\n",
    "        self.basenet.to(device)\n",
    "\n",
    "        random.seed(0)\n",
    "        pyro.set_rng_seed(0)\n",
    "\n",
    "        if self.inference == \"svi\":\n",
    "            self._train_svi(train_loader, self.epochs, self.lr, device, rel_path=rel_path, filename=filename)\n",
    "\n",
    "        elif self.inference == \"hmc\":\n",
    "            self._train_hmc(train_loader, self.n_samples, self.warmup,\n",
    "                            self.step_size, self.num_steps, device, rel_path=rel_path, filename=filename)\n",
    "\n",
    "    def evaluate(self, test_loader, device, n_samples=10, seeds_list=None):\n",
    "        self.device=device\n",
    "        self.basenet.device=device\n",
    "        self.to(device)\n",
    "        self.basenet.to(device)\n",
    "\n",
    "        random.seed(0)\n",
    "        pyro.set_rng_seed(0)\n",
    "\n",
    "        bnn_seeds=list(range(n_samples)) if seeds_list is None else seeds_list\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            correct_predictions = 0.0\n",
    "            for x_batch, y_batch in test_loader:\n",
    "\n",
    "                x_batch = x_batch.to(device)\n",
    "                outputs = self.forward(x_batch, n_samples=n_samples, seeds=bnn_seeds)\n",
    "                predictions = outputs.argmax(-1)\n",
    "                labels = y_batch.to(device).argmax(-1)\n",
    "                correct_predictions += (predictions == labels).sum().item()\n",
    "\n",
    "            accuracy = 100 * correct_predictions / len(test_loader.dataset)\n",
    "            print(\"Accuracy: %.2f%%\" % (accuracy))\n",
    "            return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/sign_mnist_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_classes = data[\"label\"].nunique()\n",
    "print(n_classes)\n",
    "data[\"label\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data[\"label\"]\n",
    "X_train = data.drop(columns =[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PARSER AND LOADER FOR THE VALUES OF SKIN\n",
    "class HandSignsDataset(Dataset):\n",
    "    def __init__(self, images, labels=None, transforms=None):\n",
    "        self.X = np.asarray(images).astype(np.float32)\n",
    "        self.y = labels\n",
    "        self.transforms = transforms\n",
    "        #print(\"GUARDA QUI\", self.y.shape)\n",
    "         \n",
    "    def __len__(self):\n",
    "        return (len(self.X))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        data = self.X[i, :]\n",
    "        data = data.reshape(28, 28, 1)\n",
    "       \n",
    "        my_y = self.y.values[i]\n",
    "        \n",
    "        if self.transforms:\n",
    "            data = self.transforms(data)\n",
    "            \n",
    "        if self.y is not None:\n",
    "            return (data, my_y)\n",
    "        else:\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pixel1    pixel2    pixel3    pixel4    pixel5    pixel6    pixel7  \\\n",
      "0      0.419608  0.462745  0.498039  0.525490  0.545098  0.560784  0.572549   \n",
      "1      0.607843  0.615686  0.611765  0.611765  0.611765  0.615686  0.611765   \n",
      "2      0.733333  0.737255  0.737255  0.733333  0.733333  0.729412  0.733333   \n",
      "3      0.827451  0.827451  0.831373  0.831373  0.827451  0.823529  0.827451   \n",
      "4      0.643137  0.654902  0.666667  0.674510  0.690196  0.701961  0.705882   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "27450  0.741176  0.741176  0.745098  0.745098  0.752941  0.756863  0.756863   \n",
      "27451  0.592157  0.603922  0.615686  0.619608  0.627451  0.631373  0.639216   \n",
      "27452  0.682353  0.682353  0.682353  0.682353  0.682353  0.686275  0.686275   \n",
      "27453  0.694118  0.709804  0.721569  0.725490  0.733333  0.741176  0.745098   \n",
      "27454  0.701961  0.705882  0.705882  0.705882  0.713725  0.709804  0.713725   \n",
      "\n",
      "         pixel8    pixel9   pixel10  ...  pixel775  pixel776  pixel777  \\\n",
      "0      0.588235  0.600000  0.611765  ...  0.811765  0.811765  0.811765   \n",
      "1      0.619608  0.619608  0.615686  ...  0.270588  0.584314  0.501961   \n",
      "2      0.737255  0.733333  0.729412  ...  0.792157  0.788235  0.784314   \n",
      "3      0.823529  0.823529  0.827451  ...  0.921569  0.917647  0.913725   \n",
      "4      0.721569  0.725490  0.729412  ...  0.360784  0.411765  0.411765   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "27450  0.756863  0.756863  0.760784  ...  0.517647  0.647059  0.388235   \n",
      "27451  0.643137  0.650980  0.654902  ...  0.776471  0.776471  0.776471   \n",
      "27452  0.682353  0.678431  0.678431  ...  0.474510  0.768627  0.819608   \n",
      "27453  0.749020  0.749020  0.745098  ...  0.466667  0.219608  0.105882   \n",
      "27454  0.717647  0.713725  0.713725  ...  0.423529  0.517647  0.666667   \n",
      "\n",
      "       pixel778  pixel779  pixel780  pixel781  pixel782  pixel783  pixel784  \n",
      "0      0.811765  0.807843  0.807843  0.807843  0.800000  0.796078  0.792157  \n",
      "1      0.341176  0.368627  0.639216  0.686275  0.403922  0.529412  0.584314  \n",
      "2      0.780392  0.776471  0.780392  0.776471  0.764706  0.760784  0.764706  \n",
      "3      0.905882  0.901961  0.886275  0.882353  0.870588  0.898039  0.639216  \n",
      "4      0.423529  0.521569  0.639216  0.615686  0.639216  0.643137  0.701961  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "27450  0.301961  0.203922  0.784314  0.917647  0.784314  0.870588  0.882353  \n",
      "27451  0.776471  0.776471  0.768627  0.764706  0.764706  0.764706  0.760784  \n",
      "27452  0.815686  0.807843  0.800000  0.796078  0.792157  0.784314  0.784314  \n",
      "27453  0.227451  0.400000  0.309804  0.184314  0.250980  0.341176  0.364706  \n",
      "27454  0.760784  0.839216  0.796078  0.772549  0.803922  0.819608  0.843137  \n",
      "\n",
      "[27455 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.get_dummies(y_train)\n",
    "X_train = X_train / 255\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.HandSignsDataset object at 0x7eff6286bd60>\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([ transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean = 0.5, std = 0.5)])\n",
    "\n",
    "\n",
    "train_data = HandSignsDataset(X_train, y_train, transform)\n",
    "#test_data = HandSignsDataset(X_test, y_test, transform)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "trainloader = DataLoader(train_data, batch_size=180, shuffle=True, generator=generator)\n",
    "#testloader = DataLoader(test_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41960785, 0.4627451 , 0.49803922, ..., 0.8       , 0.79607844,\n",
       "        0.7921569 ],\n",
       "       [0.60784316, 0.6156863 , 0.6117647 , ..., 0.40392157, 0.5294118 ,\n",
       "        0.58431375],\n",
       "       [0.73333335, 0.7372549 , 0.7372549 , ..., 0.7647059 , 0.7607843 ,\n",
       "        0.7647059 ],\n",
       "       ...,\n",
       "       [0.68235296, 0.68235296, 0.68235296, ..., 0.7921569 , 0.78431374,\n",
       "        0.78431374],\n",
       "       [0.69411767, 0.70980394, 0.72156864, ..., 0.2509804 , 0.34117648,\n",
       "        0.3647059 ],\n",
       "       [0.7019608 , 0.7058824 , 0.7058824 , ..., 0.8039216 , 0.81960785,\n",
       "        0.84313726]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_data.X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x1500 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Observing first 40 images\n",
    "figure = plt.figure(figsize=(20,15))\n",
    "num_of_images = 20\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(4, 10, index)\n",
    "    plt.axis('off')\n",
    "    I = np.asarray(train_data.X).astype(np.float32).reshape(-1,28,28,1)[index]\n",
    "    plt.imshow(I.astype('uint8'), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([180, 1, 28, 28])\n",
      "torch.Size([180, 24])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(trainloader)\n",
    "images, labels = data_iter.next()\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNN(\n",
      "  (basenet): NN(\n",
      "    (loss_func): CrossEntropyLoss()\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (4): ReLU()\n",
      "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (6): Flatten(start_dim=1, end_dim=-1)\n",
      "      (7): Linear(in_features=12800, out_features=256, bias=True)\n",
      "      (8): Linear(in_features=256, out_features=24, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BNN('SingLanguage', \"relu\", \"custom\", \"svi\", 5, 0.0007, None, None, (1,28,28), n_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " == SVI training ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/primitives.py:491: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
      "  warnings.warn(\n",
      "/home/thomas/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1660070785140/work/build/aten/src/ATen/core/TensorBody.h:477.)\n",
      "  return self._grad\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at site \"module$$$model.0.weight\", invalid log_prob shape\n  Expected [], actual [64, 1, 5, 5]\n  Try one of the following fixes:\n  - enclose the batched tensor in a with pyro.plate(...): context\n  - .to_event(...) the distribution being sampled\n  - .permute() data dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mBNN.train\u001b[0;34m(self, train_loader, device, rel_path, filename)\u001b[0m\n\u001b[1;32m    283\u001b[0m pyro\u001b[38;5;241m.\u001b[39mset_rng_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvi\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 286\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_svi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhmc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_hmc(train_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup,\n\u001b[1;32m    290\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_steps, device, rel_path\u001b[38;5;241m=\u001b[39mrel_path, filename\u001b[38;5;241m=\u001b[39mfilename)\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mBNN._train_svi\u001b[0;34m(self, train_loader, epochs, lr, device, rel_path, filename)\u001b[0m\n\u001b[1;32m    248\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    249\u001b[0m labels \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43msvi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x_batch, n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m    253\u001b[0m predictions \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m poutine\u001b[38;5;241m.\u001b[39mtrace(param_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_and_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munconstrained() \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m param_capture\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/infer/trace_elbo.py:140\u001b[0m, in \u001b[0;36mTrace_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# grab a trace from the generator\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_trace, guide_trace \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_traces(model, guide, args, kwargs):\n\u001b[1;32m    141\u001b[0m     loss_particle, surrogate_loss_particle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_differentiable_loss_particle(\n\u001b[1;32m    142\u001b[0m         model_trace, guide_trace\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_particle \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles\n",
      "File \u001b[0;32m~/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/infer/elbo.py:182\u001b[0m, in \u001b[0;36mELBO._get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles):\n\u001b[0;32m--> 182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/infer/trace_mean_field_elbo.py:82\u001b[0m, in \u001b[0;36mTraceMeanField_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, guide, args, kwargs):\n\u001b[0;32m---> 82\u001b[0m     model_trace, guide_trace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     84\u001b[0m         _check_mean_field_requirement(model_trace, guide_trace)\n",
      "File \u001b[0;32m~/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/infer/trace_elbo.py:57\u001b[0m, in \u001b[0;36mTrace_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, guide, args, kwargs):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Returns a single trace from the guide, and the model that is run\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    against it.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     model_trace, guide_trace \u001b[38;5;241m=\u001b[39m \u001b[43mget_importance_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_plate_nesting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     61\u001b[0m         check_if_enumerated(guide_trace)\n",
      "File \u001b[0;32m~/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/infer/enum.py:80\u001b[0m, in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m model_trace\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m         \u001b[43mcheck_site_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_plate_nesting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m guide_trace\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/util.py:437\u001b[0m, in \u001b[0;36mcheck_site_shape\u001b[0;34m(site, max_plate_nesting)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m actual_size, expected_size \u001b[38;5;129;01min\u001b[39;00m zip_longest(\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28mreversed\u001b[39m(actual_shape), \u001b[38;5;28mreversed\u001b[39m(expected_shape), fillvalue\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    435\u001b[0m ):\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m expected_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m expected_size \u001b[38;5;241m!=\u001b[39m actual_size:\n\u001b[0;32m--> 437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    438\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    439\u001b[0m                 [\n\u001b[1;32m    440\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat site \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, invalid log_prob shape\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m    441\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, actual \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(expected_shape, actual_shape),\n\u001b[1;32m    442\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry one of the following fixes:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    443\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- enclose the batched tensor in a with pyro.plate(...): context\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    444\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- .to_event(...) the distribution being sampled\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    445\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- .permute() data dimensions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    446\u001b[0m                 ]\n\u001b[1;32m    447\u001b[0m             )\n\u001b[1;32m    448\u001b[0m         )\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Check parallel dimensions on the left of max_plate_nesting.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m enum_dim \u001b[38;5;241m=\u001b[39m site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_enumerate_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: at site \"module$$$model.0.weight\", invalid log_prob shape\n  Expected [], actual [64, 1, 5, 5]\n  Try one of the following fixes:\n  - enclose the batched tensor in a with pyro.plate(...): context\n  - .to_event(...) the distribution being sampled\n  - .permute() data dimensions"
     ]
    }
   ],
   "source": [
    "model.train(trainloader, device, rel_path = None, filename = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.version.cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "#from savedir import *\n",
    "#from utils import *\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as nnf\n",
    "import torch.optim as torchopt\n",
    "import torch.distributions.constraints as constraints\n",
    "softplus = torch.nn.Softplus()\n",
    "\n",
    "import pyro\n",
    "from pyro import poutine\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceMeanField_ELBO, Predictive\n",
    "import pyro.optim as pyroopt\n",
    "from pyro.infer.mcmc import MCMC, HMC, NUTS\n",
    "from pyro.distributions import OneHotCategorical, Normal, Categorical, Uniform\n",
    "from pyro.nn import PyroModule\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: {}'.format(device))\n",
    "if torch.cuda.is_available():\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(dict, path):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, figsize=(12,8))\n",
    "    ax1.plot(dict['loss'])\n",
    "    ax1.set_title(\"loss\")\n",
    "    ax2.plot(dict['accuracy'])\n",
    "    ax2.set_title(\"accuracy\")\n",
    "#    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "#    fig.savefig(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "\n",
    "    def __init__(self, dataset_name, input_shape, output_size, activation, \n",
    "                 architecture, lr, epochs):\n",
    "\n",
    "#        if math.log(hidden_size, 2).is_integer() is False or hidden_size<16:\n",
    "#            raise ValueError(\"\\nhidden size should be a power of 2 greater than 16.\")\n",
    "\n",
    "        super(NN, self).__init__()\n",
    "        self.dataset_name = dataset_name\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "        # self.loss_func = nn.NLLLoss()\n",
    "        self.architecture = architecture\n",
    "#        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.activation = activation\n",
    "        self.lr, self.epochs = lr, epochs\n",
    "\n",
    "#        self.name = self.get_name(dataset_name, hidden_size, activation, architecture, lr, epochs)\n",
    "        self.set_model(architecture, activation, input_shape, output_size)\n",
    "        # print(\"\\nTotal number of weights =\", sum(p.numel() for p in self.parameters()))\n",
    "\n",
    "    def get_name(self, dataset_name, activation, architecture, lr, epochs):\n",
    "        return str(dataset_name)+\"_act=\"+str(activation)+\\\n",
    "               \"_arch=\"+str(architecture)+\"_ep=\"+str(epochs)+\"_lr=\"+str(lr)\n",
    "\n",
    "    def set_model(self, architecture, activation, input_shape, output_size):\n",
    "\n",
    "        input_size = input_shape[0]*input_shape[1]*input_shape[2]\n",
    "        in_channels = input_shape[0]\n",
    "        n_classes = output_size\n",
    "\n",
    "        if activation == \"relu\":\n",
    "            activ = nn.ReLU\n",
    "        elif activation == \"leaky\":\n",
    "            activ = nn.LeakyReLU\n",
    "        elif activation == \"sigm\":\n",
    "            activ = nn.Sigmoid\n",
    "        elif activation == \"tanh\":\n",
    "            activ = nn.Tanh\n",
    "        else: \n",
    "            raise AssertionError(\"\\nWrong activation name.\")\n",
    "\n",
    "        if architecture == \"fc\":\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(input_size, 100),\n",
    "                activ(),\n",
    "                nn.Linear(100, output_size))\n",
    "            \n",
    "        elif architecture == \"custom\":\n",
    "            self.model = nn.Sequential(nn.Conv2d(in_channels= in_channels,\n",
    "                                                 out_channels=64,\n",
    "                                                 kernel_size=5,\n",
    "                                                 ),\n",
    "                                       activ(),\n",
    "                                       nn.MaxPool2d(2,2),\n",
    "                                       #nn.BatchNorm2d(64),\n",
    "                                       nn.Conv2d(in_channels=64,\n",
    "                                                 out_channels=512,\n",
    "                                                 kernel_size=3,\n",
    "                                                 ),\n",
    "                                       activ(),\n",
    "                                       nn.MaxPool2d(2,2),\n",
    "                                       #nn.Dropout(p=0.3),\n",
    "                                       #nn.Conv2d(in_channels=512,\n",
    "                                       #          out_channels=1024,\n",
    "                                       #          kernel_size=3,\n",
    "                                       #          ),\n",
    "                                       #activ(),\n",
    "                                       #nn.MaxPool2d(2,2),\n",
    "                                       #nn.BatchNorm2d(1024),\n",
    "                                       #nn.Dropout(p=0.4),\n",
    "                                       #nn.Conv2d(in_channels=1024,\n",
    "                                       #          out_channels=1024,\n",
    "                                       #          kernel_size=2,\n",
    "                                       #          ),\n",
    "                                       #activ(),\n",
    "                                       #nn.MaxPool2d(2,2),\n",
    "                                       #nn.Dropout(p=0.4),\n",
    "                                       nn.Flatten(),\n",
    "                                       nn.Linear(512*5*5, 256),\n",
    "                                       #nn.Dropout(p=0.5),\n",
    "                                       nn.Linear(256, output_size))\n",
    "\n",
    "        elif architecture == \"conv\":\n",
    "\n",
    "            if self.dataset_name not in [\"mnist\",\"fashion_mnist\"]:\n",
    "                raise NotImplementedError()\n",
    "\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, 32, kernel_size=5),\n",
    "                activ(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(32, hidden_size, kernel_size=5),\n",
    "                activ(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(int(hidden_size/(4*4))*input_size, output_size))\n",
    "\n",
    "        elif architecture == \"conv2\":\n",
    "\n",
    "            self.model = nn.Sequential(\n",
    "\n",
    "                nn.Conv2d(in_channels, 32, kernel_size=5),\n",
    "                activ(),\n",
    "                nn.MaxPool2d(kernel_size=2), \n",
    "                nn.Conv2d(32, hidden_size, kernel_size=5),\n",
    "                activ(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "                nn.Flatten(),\n",
    "            )   \n",
    "\n",
    "            self.fc_out = lambda x: nn.Linear(x.size(1), output_size)(x)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def forward(self, inputs, device=None, *args, **kwargs):\n",
    "\n",
    "        device=self.device if device is None else device\n",
    "\n",
    "        self.to(device)\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        if self.architecture == \"conv2\":\n",
    "\n",
    "            x = self.model(inputs)\n",
    "            x = self.fc_out(x)\n",
    "\n",
    "        else:\n",
    "            x = self.model(inputs)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def save(self, savedir=None, seed=None):\n",
    "\n",
    "        name = self.name \n",
    "        directory = name if savedir is None else savedir\n",
    "        filename = name+\"_weights.pt\" if seed is None else name+\"_weights_\"+str(seed)+\".pt\"\n",
    "\n",
    "        os.makedirs(os.path.dirname(TESTS+directory+\"/\"), exist_ok=True)\n",
    "        print(\"\\nSaving: \", TESTS+directory+\"/\"+filename)\n",
    "        torch.save(self.state_dict(), TESTS+directory+\"/\"+filename)\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\"\\nCheck saved weights:\")\n",
    "            print(\"\\nstate_dict()['l2.0.weight'] =\", self.state_dict()[\"l2.0.weight\"][0,0,:3])\n",
    "            print(\"\\nstate_dict()['out.weight'] =\",self.state_dict()[\"out.weight\"][0,:3])\n",
    "\n",
    "    def load(self, device, savedir=None, seed=None, rel_path = None):   #=TESTS\n",
    "        self.device=device\n",
    "\n",
    "        name = self.name\n",
    "        directory = name if savedir is None else savedir\n",
    "        filename = name+\"_weights.pt\" if seed is None else name+\"_weights_\"+str(seed)+\".pt\"\n",
    "\n",
    "        print(\"\\nLoading: \", rel_path+directory+\"/\"+filename)\n",
    "        self.load_state_dict(torch.load(rel_path+directory+\"/\"+filename))\n",
    "        print(\"\\n\", list(self.state_dict().keys()), \"\\n\")\n",
    "        self.to(device)\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\"\\nCheck loaded weights:\")    \n",
    "            print(\"\\nstate_dict()['l2.0.weight'] =\", self.state_dict()[\"l2.0.weight\"][0,0,:3])\n",
    "            print(\"\\nstate_dict()['out.weight'] =\",self.state_dict()[\"out.weight\"][0,:3])\n",
    "\n",
    "    def train(self, train_loader, device, seed=0, save=True):\n",
    "\n",
    "        print(\"\\n == NN training ==\")\n",
    "\n",
    "        self.device=device\n",
    "        self.to(device)\n",
    "\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        optimizer = torchopt.Adam(params=self.parameters(), lr=self.lr)\n",
    "\n",
    "#        start = time.time()\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0.0\n",
    "            correct_predictions = 0.0\n",
    "\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device).argmax(-1)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.forward(x_batch, device)\n",
    "                loss = self.loss_func(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                predictions = outputs.argmax(-1)\n",
    "                correct_predictions += (predictions == y_batch).sum()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            total_loss = total_loss / len(train_loader.dataset)\n",
    "            accuracy = 100 * correct_predictions / len(train_loader.dataset)\n",
    "            print(f\"\\n[Epoch {epoch + 1}]\\t loss: {total_loss:.8f} \\t accuracy: {accuracy:.2f}\", \n",
    "                  end=\"\\t\")\n",
    "\n",
    "#        execution_time(start=start, end=time.time())\n",
    "        \n",
    "        if save:\n",
    "            self.save()\n",
    "\n",
    "    def evaluate(self, test_loader, device, *args, **kwargs):\n",
    "        self.device=device\n",
    "        self.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            correct_predictions = 0.0\n",
    "\n",
    "            for x_batch, y_batch in test_loader:\n",
    "\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device).argmax(-1)\n",
    "                outputs = self(x_batch)\n",
    "                predictions = outputs.argmax(-1)\n",
    "                correct_predictions += (predictions == y_batch).sum()\n",
    "\n",
    "            accuracy = 100 * correct_predictions / len(test_loader.dataset)\n",
    "            print(\"\\nAccuracy: %.2f%%\" % (accuracy))\n",
    "            return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN(PyroModule):\n",
    "\n",
    "    def __init__(self, dataset_name, activation, architecture, inference, \n",
    "                 epochs, lr, n_samples, warmup, input_shape, output_size, \n",
    "                 step_size=0.005, num_steps=10):\n",
    "        super(BNN, self).__init__()\n",
    "        self.dataset_name = dataset_name\n",
    "        self.inference = inference\n",
    "        self.architecture = architecture\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.n_samples = n_samples\n",
    "        self.warmup = warmup\n",
    "        self.step_size = step_size\n",
    "        self.num_steps = num_steps\n",
    "        self.basenet = NN(dataset_name=dataset_name, input_shape=input_shape, output_size=output_size,\n",
    "                          activation=activation, architecture=architecture, epochs=epochs, lr=lr)\n",
    "        # print(self.basenet)\n",
    "        self.name = self.get_name()\n",
    "\n",
    "    def get_name(self, n_inputs=None):\n",
    "        \n",
    "        name = str(self.dataset_name)+\"_bnn_\"+str(self.inference)+\"_act=\"+str(self.basenet.activation)+\\\n",
    "               \"_arch=\"+str(self.basenet.architecture)\n",
    "\n",
    "        if n_inputs:\n",
    "            name = name+\"_inp=\"+str(n_inputs)\n",
    "\n",
    "        if self.inference == \"svi\":\n",
    "            return name+\"_ep=\"+str(self.epochs)+\"_lr=\"+str(self.lr)\n",
    "        elif self.inference == \"hmc\":\n",
    "            return name+\"_samp=\"+str(self.n_samples)+\"_warm=\"+str(self.warmup)+\\\n",
    "                   \"_stepsize=\"+str(self.step_size)+\"_numsteps=\"+str(self.num_steps)\n",
    "\n",
    "    def model(self, x_data, y_data):\n",
    "\n",
    "        priors = {}\n",
    "        for key, value in self.basenet.state_dict().items():\n",
    "            loc = torch.zeros_like(value)\n",
    "            scale = torch.ones_like(value)\n",
    "            prior = Normal(loc=loc, scale=scale)\n",
    "            priors.update({str(key):prior})\n",
    "\n",
    "        lifted_module = pyro.random_module(\"module\", self.basenet, priors)()\n",
    "\n",
    "        with pyro.plate(\"data\", len(x_data)):\n",
    "            logits = lifted_module(x_data)\n",
    "            lhat = nnf.log_softmax(logits, dim=-1)\n",
    "            obs = pyro.sample(\"obs\", Categorical(logits=lhat), obs=y_data)\n",
    "\n",
    "    def guide(self, x_data, y_data=None):\n",
    "\n",
    "        dists = {}\n",
    "        for key, value in self.basenet.state_dict().items():\n",
    "            loc = pyro.param(str(f\"{key}_loc\"), torch.randn_like(value)) \n",
    "            scale = pyro.param(str(f\"{key}_scale\"), torch.randn_like(value))\n",
    "            distr = Normal(loc=loc, scale=softplus(scale))\n",
    "            dists.update({str(key):distr})\n",
    "\n",
    "        lifted_module = pyro.random_module(\"module\", self.basenet, dists)()\n",
    "        \n",
    "        with pyro.plate(\"data\", len(x_data)):\n",
    "            logits = lifted_module(x_data)\n",
    "            preds = nnf.softmax(logits, dim=-1)\n",
    "\n",
    "        return preds\n",
    "\n",
    "    def save(self, rel_path = None, filename=None):    #=TESTS\n",
    "\n",
    "        if filename is None:\n",
    "            filename = self.name+\"_weights\"\n",
    "\n",
    "        path = rel_path + self.name +\"/\"\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "        if self.inference == \"svi\":\n",
    "            self.basenet.to(\"cpu\")\n",
    "            self.to(\"cpu\")\n",
    "\n",
    "            param_store = pyro.get_param_store()\n",
    "            print(\"\\nSaving: \", path + filename +\".pt\")\n",
    "            print(f\"\\nlearned params = {param_store.get_all_param_names()}\")\n",
    "            param_store.save(path + filename +\".pt\")\n",
    "\n",
    "        elif self.inference == \"hmc\":\n",
    "            self.basenet.to(\"cpu\")\n",
    "            self.to(\"cpu\")\n",
    "\n",
    "            for key, value in self.posterior_predictive.items():\n",
    "                torch.save(value.state_dict(), path+filename+\"_\"+str(key)+\".pt\")\n",
    "\n",
    "                if DEBUG:\n",
    "                    print(value.state_dict()[\"model.5.bias\"])\n",
    "\n",
    "    def load(self, device, rel_path = None, filename=None):     #=TESTS\n",
    "\n",
    "        if filename is None:\n",
    "            filename = self.name+\"_weights\"\n",
    "\n",
    "        path = rel_path + self.name +\"/\"\n",
    "\n",
    "        self.device=device\n",
    "        self.basenet.device=device\n",
    "\n",
    "        if self.inference == \"svi\":\n",
    "            param_store = pyro.get_param_store()\n",
    "            param_store.load(path + filename + \".pt\")\n",
    "            for key, value in param_store.items():\n",
    "                param_store.replace_param(key, value.to(device), value)\n",
    "            print(\"\\nLoading \", path + filename + \".pt\\n\")\n",
    "\n",
    "        elif self.inference == \"hmc\":\n",
    "\n",
    "            self.posterior_predictive={}\n",
    "            for model_idx in range(self.n_samples):\n",
    "                net_copy = copy.deepcopy(self.basenet)\n",
    "                net_copy.load_state_dict(torch.load(path+filename+\"_\"+str(model_idx)+\".pt\"))\n",
    "                self.posterior_predictive.update({model_idx:net_copy})      \n",
    "\n",
    "            if len(self.posterior_predictive)!=self.n_samples:\n",
    "                raise AttributeError(\"wrong number of posterior models\")\n",
    "\n",
    "        self.to(device)\n",
    "        self.basenet.to(device)\n",
    "\n",
    "    def forward(self, inputs, n_samples=10, avg_posterior=False, seeds=None):\n",
    "\n",
    "        if seeds:\n",
    "            if len(seeds) != n_samples:\n",
    "                raise ValueError(\"Number of seeds should match number of samples.\")\n",
    "\n",
    "        if self.inference == \"svi\":\n",
    "\n",
    "            if avg_posterior is True:\n",
    "\n",
    "                guide_trace = poutine.trace(self.guide).get_trace(inputs)  \n",
    "\n",
    "                avg_state_dict = {}\n",
    "                for key in self.basenet.state_dict().keys():\n",
    "                    avg_weights = guide_trace.nodes[str(key)+\"_loc\"]['value']\n",
    "                    avg_state_dict.update({str(key):avg_weights})\n",
    "\n",
    "                self.basenet.load_state_dict(avg_state_dict)\n",
    "                preds = [self.basenet.model(inputs)]\n",
    "\n",
    "            else:\n",
    "\n",
    "                preds = []  \n",
    "\n",
    "                if seeds:\n",
    "                    for seed in seeds:\n",
    "                        pyro.set_rng_seed(seed)\n",
    "                        guide_trace = poutine.trace(self.guide).get_trace(inputs)   \n",
    "                        preds.append(guide_trace.nodes['_RETURN']['value'])\n",
    "\n",
    "                else:\n",
    "\n",
    "                    for _ in range(n_samples):\n",
    "                        guide_trace = poutine.trace(self.guide).get_trace(inputs)   \n",
    "                        preds.append(guide_trace.nodes['_RETURN']['value'])\n",
    "\n",
    "                if DEBUG:\n",
    "                    print(\"\\nlearned variational params:\\n\")\n",
    "                    print(pyro.get_param_store().get_all_param_names())\n",
    "                    print(list(poutine.trace(self.guide).get_trace(inputs).nodes.keys()))\n",
    "                    print(\"\\n\", pyro.get_param_store()[\"model.0.weight_loc\"][0][:5])\n",
    "                    print(guide_trace.nodes['module$$$model.0.weight'][\"fn\"].loc[0][:5])\n",
    "                    print(\"posterior sample: \", \n",
    "                      guide_trace.nodes['module$$$model.0.weight']['value'][5][0][0])\n",
    "\n",
    "        elif self.inference == \"hmc\":\n",
    "\n",
    "            preds = []\n",
    "            posterior_predictive = list(self.posterior_predictive.values())\n",
    "\n",
    "            if seeds is None:\n",
    "                seeds = range(n_samples)\n",
    "\n",
    "            for seed in seeds:\n",
    "                net = posterior_predictive[seed]\n",
    "                preds.append(net.forward(inputs))\n",
    "    \n",
    "        output_probs = torch.stack(preds).mean(0)\n",
    "        return output_probs \n",
    "\n",
    "    def _train_hmc(self, train_loader, n_samples, warmup, step_size, num_steps, device, rel_path, filename):\n",
    "\n",
    "        print(\"\\n == HMC training ==\")\n",
    "        pyro.clear_param_store()\n",
    "\n",
    "        num_batches = int(len(train_loader.dataset)/train_loader.batch_size)\n",
    "        batch_samples = int(n_samples/num_batches)+1\n",
    "        print(\"\\nn_batches=\",num_batches,\"\\tbatch_samples =\", batch_samples)\n",
    "\n",
    "        kernel = HMC(self.model, step_size=step_size, num_steps=num_steps)\n",
    "        mcmc = MCMC(kernel=kernel, num_samples=batch_samples, warmup_steps=warmup, num_chains=1)\n",
    "\n",
    "#        start = time.time()\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            labels = y_batch.to(device).argmax(-1)\n",
    "            mcmc.run(x_batch, labels)\n",
    "\n",
    "#        execution_time(start=start, end=time.time())     \n",
    "\n",
    "        self.posterior_predictive={}\n",
    "        posterior_samples = mcmc.get_samples(n_samples)\n",
    "        state_dict_keys = list(self.basenet.state_dict().keys())\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\"\\n\", list(posterior_samples.values())[-1])\n",
    "\n",
    "        for model_idx in range(n_samples):\n",
    "            net_copy = copy.deepcopy(self.basenet)\n",
    "\n",
    "            model_dict=OrderedDict({})\n",
    "            for weight_idx, weights in enumerate(posterior_samples.values()):\n",
    "                model_dict.update({state_dict_keys[weight_idx]:weights[model_idx]})\n",
    "            \n",
    "            net_copy.load_state_dict(model_dict)\n",
    "            self.posterior_predictive.update({str(model_idx):net_copy})\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\"\\n\", weights[model_idx]) \n",
    "\n",
    "        self.save(rel_path=rel_path, filename=filename)\n",
    "\n",
    "    def _train_svi(self, train_loader, epochs, lr, device, rel_path, filename):     # filename -> savedir\n",
    "        self.device=device\n",
    "\n",
    "        print(\"\\n == SVI training ==\")\n",
    "\n",
    "        optimizer = pyro.optim.Adam({\"lr\":lr})\n",
    "        elbo = TraceMeanField_ELBO()\n",
    "        svi = SVI(self.model, self.guide, optimizer, loss=elbo)\n",
    "\n",
    "        loss_list = []\n",
    "        accuracy_list = []\n",
    "\n",
    "#        start = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            loss = 0.0\n",
    "            correct_predictions = 0.0\n",
    "\n",
    "            for x_batch, y_batch in train_loader:\n",
    "\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                labels = y_batch.argmax(-1)\n",
    "                loss += svi.step(x_data=x_batch, y_data=labels)\n",
    "\n",
    "                outputs = self.forward(x_batch, n_samples=10)\n",
    "                predictions = outputs.argmax(dim=-1)\n",
    "                correct_predictions += (predictions == labels).sum().item()\n",
    "            \n",
    "            if DEBUG:\n",
    "                print(\"\\n\", pyro.get_param_store()[\"model.0.weight_loc\"][0][:5])\n",
    "                print(\"\\n\", predictions[:10], \"\\n\", labels[:10])\n",
    "\n",
    "            total_loss = loss / len(train_loader.dataset)\n",
    "            accuracy = 100 * correct_predictions / len(train_loader.dataset)\n",
    "\n",
    "            print(f\"\\n[Epoch {epoch + 1}]\\t loss: {total_loss:.2f} \\t accuracy: {accuracy:.2f}\", \n",
    "                  end=\"\\t\")\n",
    "\n",
    "            loss_list.append(loss)\n",
    "            accuracy_list.append(accuracy)\n",
    "\n",
    "#        execution_time(start=start, end=time.time())\n",
    "#        self.save(rel_path=rel_path, filename=filename)\n",
    "\n",
    "        plot_loss_accuracy(dict={'loss':loss_list, 'accuracy':accuracy_list},\n",
    "                           path = None)   # TESTS+self.name+\"/\"+self.name+\"_training.png\"\n",
    "\n",
    "    def train(self, train_loader, device, rel_path = None, filename=None):   #=TESTS\n",
    "        self.device=device\n",
    "        self.basenet.device=device\n",
    "\n",
    "        self.to(device)\n",
    "        self.basenet.to(device)\n",
    "\n",
    "        random.seed(0)\n",
    "        pyro.set_rng_seed(0)\n",
    "\n",
    "        if self.inference == \"svi\":\n",
    "            self._train_svi(train_loader, self.epochs, self.lr, device, rel_path=rel_path, filename=filename)\n",
    "\n",
    "        elif self.inference == \"hmc\":\n",
    "            self._train_hmc(train_loader, self.n_samples, self.warmup,\n",
    "                            self.step_size, self.num_steps, device, rel_path=rel_path, filename=filename)\n",
    "\n",
    "    def evaluate(self, test_loader, device, n_samples=10, seeds_list=None):\n",
    "        self.device=device\n",
    "        self.basenet.device=device\n",
    "        self.to(device)\n",
    "        self.basenet.to(device)\n",
    "\n",
    "        random.seed(0)\n",
    "        pyro.set_rng_seed(0)\n",
    "\n",
    "        bnn_seeds=list(range(n_samples)) if seeds_list is None else seeds_list\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            correct_predictions = 0.0\n",
    "            for x_batch, y_batch in test_loader:\n",
    "\n",
    "                x_batch = x_batch.to(device)\n",
    "                outputs = self.forward(x_batch, n_samples=n_samples, seeds=bnn_seeds)\n",
    "                predictions = outputs.argmax(-1)\n",
    "                labels = y_batch.to(device).argmax(-1)\n",
    "                correct_predictions += (predictions == labels).sum().item()\n",
    "\n",
    "            accuracy = 100 * correct_predictions / len(test_loader.dataset)\n",
    "            print(\"Accuracy: %.2f%%\" % (accuracy))\n",
    "            return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/sign_mnist_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_classes = data[\"label\"].nunique()\n",
    "print(n_classes)\n",
    "data[\"label\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data[\"label\"]\n",
    "X_train = data.drop(columns =[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PARSER AND LOADER FOR THE VALUES OF SKIN\n",
    "class HandSignsDataset(Dataset):\n",
    "    def __init__(self, images, labels=None, transforms=None):\n",
    "        self.X = np.asarray(images).astype(np.float32)\n",
    "        self.y = labels\n",
    "        self.transforms = transforms\n",
    "        #print(\"GUARDA QUI\", self.y.shape)\n",
    "         \n",
    "    def __len__(self):\n",
    "        return (len(self.X))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        data = self.X[i, :]\n",
    "        data = data.reshape(28, 28, 1)\n",
    "       \n",
    "        my_y = self.y.values[i]\n",
    "        \n",
    "        if self.transforms:\n",
    "            data = self.transforms(data)\n",
    "            \n",
    "        if self.y is not None:\n",
    "            return (data, my_y)\n",
    "        else:\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pixel1    pixel2    pixel3    pixel4    pixel5    pixel6    pixel7  \\\n",
      "0      0.419608  0.462745  0.498039  0.525490  0.545098  0.560784  0.572549   \n",
      "1      0.607843  0.615686  0.611765  0.611765  0.611765  0.615686  0.611765   \n",
      "2      0.733333  0.737255  0.737255  0.733333  0.733333  0.729412  0.733333   \n",
      "3      0.827451  0.827451  0.831373  0.831373  0.827451  0.823529  0.827451   \n",
      "4      0.643137  0.654902  0.666667  0.674510  0.690196  0.701961  0.705882   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "27450  0.741176  0.741176  0.745098  0.745098  0.752941  0.756863  0.756863   \n",
      "27451  0.592157  0.603922  0.615686  0.619608  0.627451  0.631373  0.639216   \n",
      "27452  0.682353  0.682353  0.682353  0.682353  0.682353  0.686275  0.686275   \n",
      "27453  0.694118  0.709804  0.721569  0.725490  0.733333  0.741176  0.745098   \n",
      "27454  0.701961  0.705882  0.705882  0.705882  0.713725  0.709804  0.713725   \n",
      "\n",
      "         pixel8    pixel9   pixel10  ...  pixel775  pixel776  pixel777  \\\n",
      "0      0.588235  0.600000  0.611765  ...  0.811765  0.811765  0.811765   \n",
      "1      0.619608  0.619608  0.615686  ...  0.270588  0.584314  0.501961   \n",
      "2      0.737255  0.733333  0.729412  ...  0.792157  0.788235  0.784314   \n",
      "3      0.823529  0.823529  0.827451  ...  0.921569  0.917647  0.913725   \n",
      "4      0.721569  0.725490  0.729412  ...  0.360784  0.411765  0.411765   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "27450  0.756863  0.756863  0.760784  ...  0.517647  0.647059  0.388235   \n",
      "27451  0.643137  0.650980  0.654902  ...  0.776471  0.776471  0.776471   \n",
      "27452  0.682353  0.678431  0.678431  ...  0.474510  0.768627  0.819608   \n",
      "27453  0.749020  0.749020  0.745098  ...  0.466667  0.219608  0.105882   \n",
      "27454  0.717647  0.713725  0.713725  ...  0.423529  0.517647  0.666667   \n",
      "\n",
      "       pixel778  pixel779  pixel780  pixel781  pixel782  pixel783  pixel784  \n",
      "0      0.811765  0.807843  0.807843  0.807843  0.800000  0.796078  0.792157  \n",
      "1      0.341176  0.368627  0.639216  0.686275  0.403922  0.529412  0.584314  \n",
      "2      0.780392  0.776471  0.780392  0.776471  0.764706  0.760784  0.764706  \n",
      "3      0.905882  0.901961  0.886275  0.882353  0.870588  0.898039  0.639216  \n",
      "4      0.423529  0.521569  0.639216  0.615686  0.639216  0.643137  0.701961  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "27450  0.301961  0.203922  0.784314  0.917647  0.784314  0.870588  0.882353  \n",
      "27451  0.776471  0.776471  0.768627  0.764706  0.764706  0.764706  0.760784  \n",
      "27452  0.815686  0.807843  0.800000  0.796078  0.792157  0.784314  0.784314  \n",
      "27453  0.227451  0.400000  0.309804  0.184314  0.250980  0.341176  0.364706  \n",
      "27454  0.760784  0.839216  0.796078  0.772549  0.803922  0.819608  0.843137  \n",
      "\n",
      "[27455 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.get_dummies(y_train)\n",
    "X_train = X_train / 255\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.HandSignsDataset object at 0x7eff6286bd60>\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([ transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean = 0.5, std = 0.5)])\n",
    "\n",
    "\n",
    "train_data = HandSignsDataset(X_train, y_train, transform)\n",
    "#test_data = HandSignsDataset(X_test, y_test, transform)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "trainloader = DataLoader(train_data, batch_size=180, shuffle=True, generator=generator)\n",
    "#testloader = DataLoader(test_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41960785, 0.4627451 , 0.49803922, ..., 0.8       , 0.79607844,\n",
       "        0.7921569 ],\n",
       "       [0.60784316, 0.6156863 , 0.6117647 , ..., 0.40392157, 0.5294118 ,\n",
       "        0.58431375],\n",
       "       [0.73333335, 0.7372549 , 0.7372549 , ..., 0.7647059 , 0.7607843 ,\n",
       "        0.7647059 ],\n",
       "       ...,\n",
       "       [0.68235296, 0.68235296, 0.68235296, ..., 0.7921569 , 0.78431374,\n",
       "        0.78431374],\n",
       "       [0.69411767, 0.70980394, 0.72156864, ..., 0.2509804 , 0.34117648,\n",
       "        0.3647059 ],\n",
       "       [0.7019608 , 0.7058824 , 0.7058824 , ..., 0.8039216 , 0.81960785,\n",
       "        0.84313726]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_data.X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x1500 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Observing first 40 images\n",
    "figure = plt.figure(figsize=(20,15))\n",
    "num_of_images = 20\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(4, 10, index)\n",
    "    plt.axis('off')\n",
    "    I = np.asarray(train_data.X).astype(np.float32).reshape(-1,28,28,1)[index]\n",
    "    plt.imshow(I.astype('uint8'), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([180, 1, 28, 28])\n",
      "torch.Size([180, 24])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(trainloader)\n",
    "images, labels = data_iter.next()\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNN(\n",
      "  (basenet): NN(\n",
      "    (loss_func): CrossEntropyLoss()\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (4): ReLU()\n",
      "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (6): Flatten(start_dim=1, end_dim=-1)\n",
      "      (7): Linear(in_features=12800, out_features=256, bias=True)\n",
      "      (8): Linear(in_features=256, out_features=24, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BNN('SingLanguage', \"relu\", \"custom\", \"svi\", 5, 0.0007, None, None, (1,28,28), n_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " == SVI training ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/primitives.py:491: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
      "  warnings.warn(\n",
      "/home/thomas/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1660070785140/work/build/aten/src/ATen/core/TensorBody.h:477.)\n",
      "  return self._grad\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at site \"module$$$model.0.weight\", invalid log_prob shape\n  Expected [], actual [64, 1, 5, 5]\n  Try one of the following fixes:\n  - enclose the batched tensor in a with pyro.plate(...): context\n  - .to_event(...) the distribution being sampled\n  - .permute() data dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mBNN.train\u001b[0;34m(self, train_loader, device, rel_path, filename)\u001b[0m\n\u001b[1;32m    283\u001b[0m pyro\u001b[38;5;241m.\u001b[39mset_rng_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvi\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 286\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_svi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhmc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_hmc(train_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup,\n\u001b[1;32m    290\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_steps, device, rel_path\u001b[38;5;241m=\u001b[39mrel_path, filename\u001b[38;5;241m=\u001b[39mfilename)\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mBNN._train_svi\u001b[0;34m(self, train_loader, epochs, lr, device, rel_path, filename)\u001b[0m\n\u001b[1;32m    248\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    249\u001b[0m labels \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43msvi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x_batch, n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m    253\u001b[0m predictions \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m poutine\u001b[38;5;241m.\u001b[39mtrace(param_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_and_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munconstrained() \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m param_capture\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/infer/trace_elbo.py:140\u001b[0m, in \u001b[0;36mTrace_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# grab a trace from the generator\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_trace, guide_trace \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_traces(model, guide, args, kwargs):\n\u001b[1;32m    141\u001b[0m     loss_particle, surrogate_loss_particle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_differentiable_loss_particle(\n\u001b[1;32m    142\u001b[0m         model_trace, guide_trace\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_particle \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles\n",
      "File \u001b[0;32m~/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/infer/elbo.py:182\u001b[0m, in \u001b[0;36mELBO._get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles):\n\u001b[0;32m--> 182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/infer/trace_mean_field_elbo.py:82\u001b[0m, in \u001b[0;36mTraceMeanField_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, guide, args, kwargs):\n\u001b[0;32m---> 82\u001b[0m     model_trace, guide_trace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     84\u001b[0m         _check_mean_field_requirement(model_trace, guide_trace)\n",
      "File \u001b[0;32m~/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/infer/trace_elbo.py:57\u001b[0m, in \u001b[0;36mTrace_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, guide, args, kwargs):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Returns a single trace from the guide, and the model that is run\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    against it.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     model_trace, guide_trace \u001b[38;5;241m=\u001b[39m \u001b[43mget_importance_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_plate_nesting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     61\u001b[0m         check_if_enumerated(guide_trace)\n",
      "File \u001b[0;32m~/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/infer/enum.py:80\u001b[0m, in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m model_trace\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m         \u001b[43mcheck_site_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_plate_nesting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m guide_trace\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tyxe_lorzo/lib/python3.9/site-packages/pyro/util.py:437\u001b[0m, in \u001b[0;36mcheck_site_shape\u001b[0;34m(site, max_plate_nesting)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m actual_size, expected_size \u001b[38;5;129;01min\u001b[39;00m zip_longest(\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28mreversed\u001b[39m(actual_shape), \u001b[38;5;28mreversed\u001b[39m(expected_shape), fillvalue\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    435\u001b[0m ):\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m expected_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m expected_size \u001b[38;5;241m!=\u001b[39m actual_size:\n\u001b[0;32m--> 437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    438\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    439\u001b[0m                 [\n\u001b[1;32m    440\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat site \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, invalid log_prob shape\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m    441\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, actual \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(expected_shape, actual_shape),\n\u001b[1;32m    442\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry one of the following fixes:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    443\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- enclose the batched tensor in a with pyro.plate(...): context\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    444\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- .to_event(...) the distribution being sampled\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    445\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- .permute() data dimensions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    446\u001b[0m                 ]\n\u001b[1;32m    447\u001b[0m             )\n\u001b[1;32m    448\u001b[0m         )\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Check parallel dimensions on the left of max_plate_nesting.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m enum_dim \u001b[38;5;241m=\u001b[39m site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_enumerate_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: at site \"module$$$model.0.weight\", invalid log_prob shape\n  Expected [], actual [64, 1, 5, 5]\n  Try one of the following fixes:\n  - enclose the batched tensor in a with pyro.plate(...): context\n  - .to_event(...) the distribution being sampled\n  - .permute() data dimensions"
     ]
    }
   ],
   "source": [
    "model.train(trainloader, device, rel_path = None, filename = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.version.cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tyxe_lorzo",
   "language": "python",
   "name": "tyxe_lorzo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
