{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sld_bcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "#cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.006] global /home/conda/feedstock_root/build_artifacts/libopencv_1671406904936/work/modules/videoio/src/cap_v4l.cpp (902) open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 108\u001b[0m\n\u001b[1;32m    105\u001b[0m ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread() \u001b[39m#Capture each frame\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m fps \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m:\n\u001b[0;32m--> 108\u001b[0m     image        \u001b[39m=\u001b[39m frame[\u001b[39m100\u001b[39;49m:\u001b[39m450\u001b[39;49m,\u001b[39m150\u001b[39;49m:\u001b[39m570\u001b[39;49m]\n\u001b[1;32m    109\u001b[0m     image_data   \u001b[39m=\u001b[39m preprocess(image)\n\u001b[1;32m    110\u001b[0m     prediction   \u001b[39m=\u001b[39m sld_bcnn\u001b[39m.\u001b[39mbnn\u001b[39m.\u001b[39mpredict(image_data, num_predictions\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import PIL \n",
    "import cv2\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "import base64\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "\n",
    "#This is the Label\n",
    "Labels = { 0 : 'A',\n",
    "           1 : 'B',\n",
    "           2 : 'C',\n",
    "           3 : 'D',\n",
    "           4 : 'E',\n",
    "           5 : 'F',\n",
    "           6 : 'G',\n",
    "           7 : 'H',\n",
    "           8 : 'I',\n",
    "           9 : 'K',\n",
    "           10: 'L',\n",
    "           11: 'M',\n",
    "           12: 'N',\n",
    "           13: 'O',\n",
    "           14: 'P',\n",
    "           15: 'Q',\n",
    "           16: 'R',\n",
    "           17: 'S',\n",
    "           18: 'T',\n",
    "           19: 'U',\n",
    "           20: 'V',\n",
    "           21: 'W',\n",
    "           22: 'X',\n",
    "           23: 'Y'\n",
    "        }\n",
    "\n",
    "# Let's preprocess the inputted frame\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(28),\n",
    "        transforms.CenterCrop((28, 28)),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5],[0.5])\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")   ##Assigning the Device which will do the calculation\n",
    "# model  = torch.load(\"Resnet50_Left_Pretrained_ver1.1.pth\") #Load model to CPU\n",
    "# model  = model.to(device)   #set where to run the model and matrix calculation\n",
    "# model.eval()                #set the device to eval() mode for testing\n",
    "\n",
    "def arrayShow (imageArray):\n",
    "    ret, png = cv2.imencode('.png', imageArray)\n",
    "    encoded = base64.b64encode(png)\n",
    "    return Image(data=png)\n",
    "\n",
    "\n",
    "#Set the Webcam \n",
    "def Webcam_720p():\n",
    "    cap.set(3,640)\n",
    "    cap.set(4,480)\n",
    "\n",
    "def argmax(prediction):\n",
    "    prediction = prediction.cpu()\n",
    "    prediction = prediction.detach().numpy()\n",
    "    top_1 = np.argmax(prediction, axis=1)\n",
    "    score = np.amax(np.exp(prediction))\n",
    "    #score = '{:6f}'.format(score)\n",
    "    prediction = top_1[0]\n",
    "    result = Labels[prediction]\n",
    "\n",
    "    return result,score\n",
    "\n",
    "\n",
    "def preprocess(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = PIL.Image.fromarray(image) #Webcam frames are numpy array format\n",
    "                                       #Therefore transform back to PIL image\n",
    "    print(image)                             \n",
    "    image = data_transforms(image)\n",
    "    image = image.float()\n",
    "    #image = Variable(image, requires_autograd=True)\n",
    "    image = image.cuda()\n",
    "    image = image.unsqueeze(0) #I don't know for sure but Resnet-50 model seems to only\n",
    "                               #accpets 4-D Vector Tensor so we need to squeeze another\n",
    "    return image                            #dimension out of our 3-D vector Tensor\n",
    "    \n",
    "    \n",
    "#Let's start the real-time classification process!\n",
    "                                  \n",
    "cap = cv2.VideoCapture(0) #Set the webcam\n",
    "Webcam_720p()\n",
    "\n",
    "fps = 0\n",
    "show_score = 0\n",
    "show_res = 'Nothing'\n",
    "sequence = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() #Capture each frame\n",
    "    \n",
    "    if fps == 5:\n",
    "        image        = frame[100:450,150:570]\n",
    "        image_data   = preprocess(image)\n",
    "        prediction   = sld_bcnn.bnn.predict(image_data, num_predictions=10)\n",
    "        result,score = argmax(prediction)\n",
    "        print(str(result) + str(score))\n",
    "        fps = 0\n",
    "        if score >= 0.5:\n",
    "            show_res  = result\n",
    "            show_score= '{:6f}'.format(score)\n",
    "        else:\n",
    "            show_res   = \"Nothing\"\n",
    "            show_score = '{:6f}'.format(score)\n",
    "            \n",
    "        cv2.putText(frame, '%s' %(show_score),(100,100), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 3)\n",
    "        cv2.putText(frame, '%s' %(show_res),(100,250), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 3)\n",
    "            \n",
    "        try:\n",
    "            clear_output(wait=True)\n",
    "            #l=[]\n",
    "            #bnn_sight = arrayShow(np.array(image_data.cpu()))\n",
    "            img = arrayShow(frame)\n",
    "            display(img)\n",
    "            \n",
    "            # grid = torchvision.utils.make_grid(image_data.cpu())\n",
    "            # plt.figure(figsize=(8,8))\n",
    "            # plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "            \n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            video.release()\n",
    "        \n",
    "    fps += 1\n",
    "\n",
    "    #cv2.putText(frame, '(score = %.5f)' %(show_score), (100,300), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2)\n",
    "    #cv2.rectangle(frame,(200,150),(100,200), (250,0,0), 2)\n",
    "    #cv2.imshow(\"ASL SIGN DETECTER\", frame)\n",
    "    \n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "    #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "     #   break\n",
    "\n",
    "\n",
    "\n",
    "#cap.release()\n",
    "#cv2.destroyWindow(\"ASL SIGN DETECTER\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tyxe_sld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc664fa5b2e1372abf28c70c515bcbf974f9c01ff999c238247c6f5b29914d4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
