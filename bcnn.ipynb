{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import torchvision\n",
    "import preprocessing\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "import bcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: 20000\n",
      "val_data: 7455\n",
      "test_data: 7172\n"
     ]
    }
   ],
   "source": [
    "train_path = r'data/sign_mnist_train.csv'\n",
    "test_path = r'data/sign_mnist_test.csv'\n",
    "\n",
    "images_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.RandomHorizontalFlip(), \n",
    "    torchvision.transforms.RandomRotation(10), \n",
    "])\n",
    "\n",
    "labels_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "train_data_full = preprocessing.ASLDataset(\n",
    "    csv_file=train_path, \n",
    "    transform=images_transforms, \n",
    "    target_transform=None\n",
    "    )\n",
    "\n",
    "test_data = preprocessing.ASLDataset(\n",
    "    csv_file=test_path, \n",
    "    transform=images_transforms, \n",
    "    target_transform=None\n",
    "    )\n",
    "\n",
    "\n",
    "val_size = 7455\n",
    "train_size = len(train_data_full) - val_size\n",
    "\n",
    "train_data, val_data = random_split(train_data_full, [train_size, val_size])\n",
    "print('train_data:', len(train_data))\n",
    "print('val_data:', len(val_data))\n",
    "print('test_data:', len(test_data))\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bcnn.BCNN()\n",
    "guide = AutoDiagonalNormal(model)\n",
    "optim = pyro.optim.Adam({\"lr\": 0.03})\n",
    "svi = SVI(model, guide, optim, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  Loss  17182.23447291355\n",
      "Epoch  1  Loss  6735.6542171504025\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "\n",
    "num_iterations = 2\n",
    "loss = 0\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    loss = 0\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        # calculate the loss and take a gradient step\n",
    "        loss += svi.step(images, labels)\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = loss / normalizer_train\n",
    "    \n",
    "    print(\"Epoch \", j, \" Loss \", total_epoch_loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Predictive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/azad/Documents/SLD/bcnn.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/azad/Documents/SLD/bcnn.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictive \u001b[39m=\u001b[39m Predictive(model, guide\u001b[39m=\u001b[39mguide, num_samples\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/azad/Documents/SLD/bcnn.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (images, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/azad/Documents/SLD/bcnn.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     preds \u001b[39m=\u001b[39m predictive(images)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Predictive' is not defined"
     ]
    }
   ],
   "source": [
    "predictive = Predictive(model, guide=guide, num_samples=500)\n",
    "for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "    preds = predictive(images)\n",
    "    print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sampled_models = [guide(None, None) for _ in range(10)]\n",
    "print(type(sampled_models))\n",
    "print(len(sampled_models))\n",
    "print(list(sampled_models[3].keys()))\n",
    "#print(sampled_models[2])\n",
    "\n",
    "for j, (images, labels) in enumerate(test_loader):\n",
    "    for model in sampled_models:\n",
    "        print(type(model))\n",
    "        out = model(images)\n",
    "        print(out)\n",
    "\n",
    "\n",
    "num_samples = 10\n",
    "def predict(x):\n",
    "    sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
    "    yhats = [model(x) for model in sampled_models]\n",
    "    mean = torch.mean(torch.stack(yhats), 0)\n",
    "    return np.argmax(mean.numpy(), axis=1)\n",
    "\n",
    "print('Prediction when network is forced to predict')\n",
    "correct = 0\n",
    "total = 0\n",
    "for j, data in enumerate(test_loader):\n",
    "    images, labels = data\n",
    "    predicted = predict(images)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print(\"accuracy: %d %%\" % (100 * correct / total))\n",
    "\n",
    "\n",
    "from pyro.infer import Predictive\n",
    "\n",
    "guide.requires_grad_(False)\n",
    "predictive = Predictive(model, guide=guide, num_samples=1000, return_sites=(\"linear.weight\", \"obs\", \"_RETURN\"))\n",
    "\n",
    "distribution = dist.Normal(torch.zeros(1, device='cpu'), torch.ones(1, device='cpu'))\n",
    "\n",
    "for module_name, module in net.named_modules():\n",
    "    for param_name, param in list(module.named_parameters(recurse=False)):\n",
    "        full_name = module_name + \".\" + param_name\n",
    "        #print('module:', module)\n",
    "        #print('param_name:', param_name)\n",
    "        #print('Full_name:', full_name)\n",
    "        #print('param.shape:', param.shape)\n",
    "        #print('param.dim():', param.dim())\n",
    "        prior_dist = distribution.expand(param.shape).to_event(param.dim())\n",
    "        #print(prior_dist)\n",
    "        setattr(module, param_name, PyroSample(prior_dist))\n",
    "\n",
    "#print(torchsummary.summary(net, (1, 28, 28)))\n",
    "'''\n",
    "print('hello')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d6f7e2b19f5583e90f0e1c45935e0e2e666c556fd2ef0f9241dac243ca3abe7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
